# QuotesBot

This is a Scrapy project to scrape quotes from famous people from http://quotes.toscrape.com ([github repo](https://github.com/scrapinghub/spidyquotes)).

This project is only meant for educational purposes.

## What's New

This updated version includes spiders that demonstrate modern web scraping techniques essential for today's websites:

- **JavaScript Rendering**: Extract data from pages where content is dynamically generated by JavaScript
- **API Integration**: Work with infinite scroll pages using API endpoints and JSON responses
- **Authentication**: Handle login forms with CSRF token protection
- **Table Parsing**: Scrape structured data from HTML tables
- **ViewState Forms**: Deal with ASP.NET ViewState in form submissions
- **Dynamic Content**: Fetch random or changing content from endpoints

These additions make QuotesBot a comprehensive learning resource for students tackling real-world web scraping challenges.


## Extracted data

This project extracts quotes, combined with the respective author names and tags.
The extracted data looks like this sample:

    {
        'author': 'Douglas Adams',
        'text': '“I may not have gone where I intended to go, but I think I ...”',
        'tags': ['life', 'navigation']
    }


## Spiders

This project contains several spiders and you can list them using the `list`
command:

    $ scrapy list
    toscrape-css
    toscrape-xpath
    toscrape-scroll
    toscrape-js
    toscrape-login
    toscrape-table
    toscrape-viewstate
    toscrape-random

Each spider targets a different endpoint or challenge on the website:

### Basic Spiders
- **`toscrape-css`**: Standard scraping using CSS selectors for beginners
- **`toscrape-xpath`**: Standard scraping using XPath expressions as an alternative to CSS

### Advanced Spiders (Modern Techniques)
- **`toscrape-scroll`**: Scrapes quotes from the infinite scrolling page by directly calling the API endpoint (`/api/quotes`) and parsing JSON responses
- **`toscrape-js`**: Extracts data from JavaScript-rendered content by parsing embedded JSON in `<script>` tags
- **`toscrape-login`**: Demonstrates form-based authentication with automatic CSRF token handling using `FormRequest.from_response()`
- **`toscrape-table`**: Parses quotes from table layouts by iterating through rows and extracting data from cells
- **`toscrape-viewstate`**: Handles ASP.NET ViewState forms by extracting and submitting hidden form fields
- **`toscrape-random`**: Scrapes a single random quote from the `/random` endpoint

### Learning Path

1. **Start with basics**: Run `toscrape-css` and `toscrape-xpath` to understand fundamental Scrapy concepts
2. **Progress to modern challenges**: Try the advanced spiders to learn techniques for:
   - Handling JavaScript-heavy websites
   - Working with APIs and JSON data
   - Managing authentication flows
   - Parsing complex layouts
   - Dealing with form-based navigation

You can learn more about Scrapy fundamentals by going through the
[Scrapy Tutorial](http://doc.scrapy.org/en/latest/intro/tutorial.html).


## Installation

First, clone the repository and install the required dependencies:

```bash
git clone https://github.com/yourusername/quotesbot.git
cd quotesbot
pip install scrapy
```

## Running the spiders

You can run a spider using the `scrapy crawl` command, such as:

    $ scrapy crawl toscrape-css

If you want to save the scraped data to a file, you can pass the `-o` option:
    
    $ scrapy crawl toscrape-css -o quotes.json

### Example Commands

```bash
# Basic scraping with CSS selectors
scrapy crawl toscrape-css -o quotes-css.json

# Scrape JavaScript-rendered content
scrapy crawl toscrape-js -o quotes-js.json

# Scrape with authentication
scrapy crawl toscrape-login -o quotes-login.json

# Scrape using API (infinite scroll)
scrapy crawl toscrape-scroll -o quotes-scroll.json

# Scrape from table layout
scrapy crawl toscrape-table -o quotes-table.json
```

## Tips for Students

- **Compare CSS vs XPath**: Run both `toscrape-css` and `toscrape-xpath` to see different selector strategies
- **Inspect the target websites**: Use browser DevTools to understand page structure before writing selectors
- **Check the API**: For `toscrape-scroll`, visit `http://quotes.toscrape.com/api/quotes?page=1` in your browser to see the JSON structure
- **Authentication testing**: The login credentials for `toscrape-login` are typically test credentials provided by the site
- **Experiment safely**: This sandbox is designed for learning, so feel free to modify and experiment with the spiders
